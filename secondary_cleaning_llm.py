"""
ç”¨å¤§æ¨¡å‹å¯¹ç›¸ä¼¼åº¦è®¡ç®—æ•°æ®é›†è¿›è¡ŒäºŒæ¬¡æ¸…æ´—ï¼Œè¿‡æ»¤æ‰è´Ÿæ ·æœ¬ä¸­ä¸queryè¯­ä¹‰ç›¸åŒçš„æ ·æœ¬
"""
import json

import os
import random
import time
import pandas as pd

os.environ["OPENAI_API_KEY"] = 'YOUR_OPENAI_KEY'
from langchain.chat_models import ChatOpenAI
from openai import OpenAI


class ChatGPT():
    # llm = ChatOpenAI(model_name="gpt-4-1106-preview")
    client = OpenAI()
    def predict(self,text):

        response = self.client.chat.completions.create(
            model="gpt-4o",  # gpt-4-1106-preview   gpt-3.5-turbo
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content":text},
            ],
            response_format={"type": "json_object"},  # ğŸ‘ˆ å…³é”®ï¼šå¼ºåˆ¶ JSON è¾“å‡º
            temperature=0.0  # é™ä½éšæœºæ€§ï¼Œæé«˜ä¸€è‡´æ€§
        )
        rsp = response.choices[0].message.content
        print(response.usage)
        return rsp


llm = ChatGPT()

# è¿™ä¸ª Prompt çš„ç›®çš„æ˜¯æŠŠâ€œé•¿å¾—åƒä½†è¯­ä¹‰ä¸åŒâ€çš„çœŸæ­£ç¡¬è´Ÿæ ·æœ¬æŒ‘å‡ºæ¥ï¼Œå‰”é™¤é‚£äº›â€œé•¿å¾—åƒä¸”è¯­ä¹‰ä¹Ÿä¸€è‡´â€çš„æ½œåœ¨æ­£æ ·æœ¬ã€‚
prompt_neg = """ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„è¯­ä¹‰åŒ¹é…ä¸“å®¶ã€‚è¯·åˆ¤æ–­ä»¥ä¸‹ Queryï¼ˆç”¨æˆ·æŸ¥è¯¢ï¼‰ä¸ Candidateï¼ˆå€™é€‰æ–‡æ¡£ï¼‰ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ã€‚
åˆ¤æ–­æ ‡å‡†ï¼š
å®Œå…¨åŒ¹é… (Match)ï¼šä¸¤è€…è¡¨è¾¾çš„æ„æ€å®Œå…¨ä¸€è‡´ï¼Œæˆ–è€… Candidate å®Œç¾å›ç­”äº† Queryã€‚
éƒ¨åˆ†ç›¸å…³ (Partial)ï¼šè¯é¢˜ç›¸å…³ï¼Œä½†å…·ä½“æ„å›¾ä¸åŒï¼ˆä¾‹å¦‚ï¼šä¿®æ”¹æ”¯ä»˜å¯†ç  vs ä¿®æ”¹ç™»å½•å¯†ç ï¼‰ã€‚
ä¸ç›¸å…³ (Irrelevant)ï¼šè¯é¢˜å®Œå…¨ä¸åŒã€‚

è¾“å…¥ï¼š
Query: "{query}"
Candidate: "{neg_text}"
è¾“å‡ºè¦æ±‚ï¼š è¯·ä»…è¾“å‡º JSON æ ¼å¼ï¼ŒåŒ…å« labelï¼ˆå–å€¼ä¸º "å®Œå…¨åŒ¹é…", "éƒ¨åˆ†ç›¸å…³", "ä¸ç›¸å…³"ï¼‰å’Œ reasonï¼ˆç®€çŸ­ç†ç”±ï¼‰ã€‚
æ³¨æ„ï¼š åªæœ‰å½“ label ä¸º "éƒ¨åˆ†ç›¸å…³" æˆ– "ä¸ç›¸å…³" æ—¶ï¼Œè¯¥å€™é€‰æ–‡æ¡£æ‰èƒ½ä½œä¸ºè´Ÿæ ·æœ¬ã€‚å¦‚æœ label ä¸º "å®Œå…¨åŒ¹é…"ï¼Œè¯·åŠ¡å¿…æ ‡è®°ã€‚"""
def verify_data(item):
    query = item['query']
    pos_list = item['pos']
    neg_list = item['neg']

    clean_negs = []
    for neg in neg_list:
        # è°ƒç”¨ LLM è¿›è¡Œè´Ÿæ ·æœ¬æ ¡éªŒ
        # print(prompt_neg.format(query=query, neg_text = neg))

        response = llm.predict(prompt_neg.format(query=query, neg_text=neg))
        # print(response)
        response_json = json.loads(response)
        # åªæœ‰çœŸæ­£ä¸ç›¸å…³çš„æ‰ä¿ç•™
        if response_json['label'] in ["éƒ¨åˆ†ç›¸å…³", "ä¸ç›¸å…³"]:
            clean_negs.append(neg)

    if len(clean_negs) > 0:
        return {
            "query": query,
            "pos": pos_list,
            "neg": clean_negs
        }
    return None

# item = {"query": "è¯¢é—®è£…ä¿®ç¨‹åº¦ã€‚", "pos": ["è¯¢é—®è£…ä¿®ç¨‹åº¦ã€‚"], "neg": ["è£…ä¿®æ ‡å‡†æ˜¯å¤šå°‘é’±ï¼Ÿ", "å¸¦è£…ä¿®å—ï¼Ÿæ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ", "è£…ä¿®äº¤ä»˜ä»€ä¹ˆæ ‡å‡†ï¼Ÿ", "{å¯é€‰è£…ä¿®æƒ…å†µ}{ç”¨å“å‘³è£…ä¿®}{æˆ¿å‹ç‰¹ç‚¹}", "è£…ä¿®æ ‡å‡†ç®€å•ä»‹ç»"]}
# verify_data(item)
# å¤„ç†å¹¶ä¿å­˜
with open('./finetune_data_cleaned.jsonl', 'r', encoding='utf-8') as f:
    raw_mined_data = f.readlines()
    # print(raw_mined_data)


with open('./final_bge_train_data.jsonl', 'w', encoding='utf-8') as f:
    i = 0
    length = len(raw_mined_data)
    for item in raw_mined_data:
        i += 1
        print("è¿›åº¦:{}/{}".format(i, length))
        verified_item = verify_data(json.loads(item))
        if verified_item:
            f.write(json.dumps(verified_item, ensure_ascii=False) + '\n')
